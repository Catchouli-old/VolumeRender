\chapter{Introduction}
\label{intro}
This dissertation investigates the application of real time ray tracing to volume data. We describe the implementation of a ray tracer that can ray trace volumetric data at real time, producing a variety of visual effects. We also describe the problems encountered due to the adaptation of 3D volume data and the possible solutions we came up with.

\section{Rasterisation}
Rasterisation is currently the most popular technique for producing real-time 3D computer graphics. It involves the tessellation of surfaces into triangles, which are then rendered to the screen by means of rasterisation. Each pixel is then shaded using an approximation of how light would be reflected off of each surface.

\section{Ray casting}
Ray casting, a technique pioneered by \cite{appel68raytracing}, on the other hand aims to simulate the path of light by casting a ray, known as an eye ray, from the eye to the surface in order to determine visibility. This simulates the path of light in reverse, as in nature light follows the path from a light source to the surface before being reflected to the eye of an observer. By following the reverse of this ray, a physically accurate representation of this scene can be produced with a finite number of rays \parencite{appel68raytracing}.

\subsection{Method}
Although numerous works have expanded on and optimised the technique, the main steps are as follows.

% Hide number from itemize list item
\let\oldlabelitemi\labelitemi
\renewcommand{\labelitemi}{}

\begin{itemize}
	\item For each pixel of the screen:

	\begin{enumerate}
		\item Calculate a ray from the viewer through the near-view plane
		\item Find the nearest intersection of this ray with the scene
		\item Pass details of this intersection to a shader to be shaded
	\end{enumerate}
\end{itemize}

% Restore old itemize list item style
\let\labelitemi\oldlabelitemi

The shading can then be accomplished using the same techniques used in rasterisation. (See Section \ref{implementation} for our implementation.)

\subsection{Ray tracing}
Additionally, ray casting can be extended into a technique called ray tracing, in which secondary rays are spawned from points of intersection, including light rays for determining whether an area is in shadow, reflection rays for simulating the reflection of light from other surfaces, and refraction rays, for determining the distance through an object which light is refracted.

A common approach for implementing this is to call the ray cast function from the shader, recursively calling the shader function. This allows the existing ray casting and shading functions to be used to implement these techniques, making them extremely simple to implement on top of an existing ray caster.

\subsection{Path tracing}

\subsection{Comparison of techniques}

\subsubsection{Per-pixel shading}
Ray casting is, by definition, per-pixel, as each pixel in the rendered image is represented by its own ray \parencite{appel68raytracing}. This lends itself well to per-pixel shading models, and allows it to produce smoothly shaded surfaces with techniques that necessitate smooth normals such as specular highlights. Additionally, there is no need for techniques such as deferred shading, as each pixel on the screen needs only to be shaded once.

\subsubsection{Point sampling}
Despite the per-pixel nature of ray casting/tracing providing several advantages, it produces one major disadvantage. It is a point-sampling method \parencite{amanatides84conetracing}. This means that each ray only samples data from the single point that it hits, without taking into account the area around the hit point as one would expect due to the nature of perspective. Although the shading is still smooth due to the per-pixel nature of ray casting, the edges of objects often appear rough and aliased \parencite{amanatides84conetracing}.

Researchers have found numerous methods for dealing with this, including adapting anti-aliasing approaches \parencite{laine10efficientsvos}, modelling rays as cones \parencite{amanatides84conetracing}, distributing rays around the focal point \parencite{cook84distributed}, and calculating the lighting using an integral equation (a technique called path tracing) \parencite{kajiya86therendering}.

As pointed out by \cite{cook84distributed}, the precisely determined nature of ray tracing has also limited the capabilities of ray tracing in other ways. For example, simple ray tracing produces shadows with unrealistic, hard edges. A technique presented by \cite{kajiya86therendering} called path tracing solves this problem by considering the shading for each pixel as an integral over an area. This has the effect of extending the range of optical phenomena that can be realistically simulated. Kajiya's algorithm uses a Monte Carlo solution in order to do this however, and as such, it requires a large number of rays to be traced in order to produce this realistic result, making it unsuitable for real time effects.

Approaches to solving these problems will be explored in greater detail in Chapter~\ref{litreview}.

\section{3D object representation schemes}
Despite rasterisation only being applicable to simple polygon representations such as triangles, ray casting/tracing has the potential to work with other types of data structures including truly volumetric data. The following is a summary of these structures.

\subsection{Polygons}
Polygons, triangles specifically, are the traditional structure in which 3D model data is stored. By tessellating a surface into a sufficient number of triangles, an adequate approximation can be obtained for any surface in a homogeneous manner, unlike older approaches such as boolean trees of mathematical 3D shapes \parencite{meagher81octree} which were anything but homogeneous.

\subsubsection{Real time effects}
The problem with calculating real time effects for rasterisation is that each polygon is considered separately, and as such, extra computation must be applied in order to obtain any sort of approximation of effects which require knowledge of any other part of the scene.

In comparison, ray casting considers the whole scene and works its way to a surface to sample. Because of this, it is simply extensible to visual effects which must consider the scene around the sampled point.

\subsubsection{Scaling}
Simple rasterisation and ray casting with polygons scales linearly with the number of polygons, as each polygon must be processed individually for rasterisation, and each polygon must be checked for intersection with the ray in ray casting.

Even with techniques such as occlusion culling, which reduce the amount of the scene that rasterisation must process by determining surfaces which can not be visible, the rendering time for rasterisation increases linearly with the detail as smaller and more polygons must be added to produce more detail. Despite this, polygons do have an advantage for large surfaces with little detail, as a polygon of any size can be rasterised.

Space subdivision techniques however have been applied to ray casting such as \cite{glassner84space}, which uses an octree, (a structure which was presented by \cite{meagher80octree} as a structure for representing 3D space hierarchically, and that will be examined later in the section,) in order to subdivide space, reducing the number of polygons a particular ray must be checked for intersection with. Although this is an effective technique for speeding up the ray casting of large numbers of polygons, some researchers have questioned whether it would not be better to encode the volumes directly using these structures and have investigated means to efficiently do so \parencite{laine10efficientsvos}.

\subsection{Volumetric structures}
Some of the earliest structures for encoding 3D data for computer graphics were volumetric in nature. \cite{meagher81octree} gives a good overview of structures of the time, as well as presenting his own, octrees, which we have chosen to implement for the purposes of this project.

Ignoring those approaches which lack homogeneity, and as such are difficult to render efficiently, for example approaches which attempt to combine a variety of mathematical objects to produce a single object as described in \cite{meagher81octree}, there are a number of structures for consideration. Two major categories of volumetric structures are non-hierarchical structures, structures which store data at a particular fixed resolution, and non-hierarchical structures, structures which encode data at a higher resolution as one traverses deeper into the structure.

\subsubsection{Non-hierarchical structures}
The primary non-hierarchical structure which is used to encode volume data is the 3D array. The 3D array has some advantages as a simple data structure. It is simple to cast rays through intuitively, as the data within is laid out in a simple grid. Additionally, this structure may be suitable for where the data does not need to be a particularly high resolution, or for data of a fixed resolution where adaptively changing the resolution of the data does not provide any benefit.

Despite its advantages as a simple data structure, the array has some major limitations. Firstly, empty space is encoded using the same amount of storage as non-empty space. Generally, no attributes need to be stored to describe empty space, so it makes sense to not encode it if possible. Additionally, as previously suggested, the resolution is fixed so data of a high resolution must be stored entirely at that resolution. This causes this approach to have a much higher memory footprint than necessary.

\subsubsection{Hierarchical structures}

\paragraph{The octree}
The octree is a structure proposed by \cite{meagher81octree} which stores data hierarchically by dividing space into eight octants at each level in the hierarchy. In other words, space is divided once along each axis to produce $2^3 = 8$ octants.

This provides the advantage that the resolution of the data is dynamic, as the tree can be deeper for parts of the scene which need to be at a higher resolution \parencite{laine10efficientsvos}. Additional advantages include automatic LOD, as the traversal of the structure can stop as soon as a voxel is found that is smaller than the pixel \parencite{laine10efficientsvos}.

\paragraph{Sparse structures}
The major advantage of using a hierarchical structure is that empty space need not be encoded. By not encoding empty space, it can be skipped at the highest resolution possible, making the ray cast more efficient as well as greatly reducing the memory footprint of the structure.

\paragraph{Subsurfaces}
In addition to not needing to store empty space, for the purposes of games, volume under the surface need not be stored, as it will never be seen. Despite this, all techniques in this paper will also work for data which does contain subsurfaces.

\subsection{Comparison of structures}

\paragraph{Deformation}
One major advantage of polygon-based structures is the ease at which deformation is possible. As vertices can be moved without producing gaps in the surface, due to the fact that vertices are generally shared between polygons in polygon-based representations, polygon meshes can be easily deformed to produce animation.

On the other hand, deforming volumes leaves problematic gaps between voxels, making the use of volume structures for animations problematic. Additionally, storing separate volumes as frames of animation is prohibitively expensive in terms of memory footprint. Despite this, a method has been presented by \cite{bautembach2011animated}, in which parent voxels are automatically scaled to contain their child voxels as the volume is deformed. Bautembach demonstrates some convincing evidence that, using this technique, complex animation techniques as used in character animation may be possible with hierarchical volume structures.